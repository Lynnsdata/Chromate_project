{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 작업 계획 세우기\n",
    "\n",
    "1. Linux 파일 시스템에 저장된 공정 환경변수 파일들을 하루 한 번 MySQL에 정기적으로 저장\n",
    "    - 저장된 공정 환경변수 파일들을 전처리\n",
    "    - 전처리된 것을 parquet 형식으로 Hadoop에 저장\n",
    "    - 전처리된 것을 SQL Alchemy로 pd.to_sql() 해서 MySQL에 저장(원래 테이블에 insert)\n",
    "        - MySQL query를 select ~ 해서 parquet 형식으로 만들어 모델러에게 줄 수 있게 해보자\n",
    "2. 업로드가 전부 완료되면 Linux 파일 시스템에서 공정 환경변수 파일들 삭제\n",
    "\n",
    "우선 여기서는 폴더 파일을 사용하여 해본 후,\n",
    "나중에 Linux 파일 시스템이 만들어지면 그걸로 바꾸면 됨\n",
    "\n",
    "<a href=\"https://airflow.apache.org/docs/apache-airflow/stable/howto/set-up-database.html\">airflow 공식문서 링크</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 패키지\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from time import strftime\n",
    "\n",
    "# 추가 패키지\n",
    "import pyarrow\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# 디렉토리 관련 패키지\n",
    "import os\n",
    "import glob\n",
    "import natsort\n",
    "\n",
    "# MySQL 관련 패키지\n",
    "import MySQLdb\n",
    "import mysql.connector\n",
    "\n",
    "# SQL Alchemy 관련 패키지 1\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.dialects.mysql import *\n",
    "from sqlalchemy.types import *\n",
    "\n",
    "# SQL Alchemy 관련 패키지 2\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import Table, MetaData\n",
    "from sqlalchemy import insert, update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MySQL 스케줄러"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] SQL Alchemy 연결 | Scheduler ON | Timezone 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) SQL Alchemy 연결 - 함수 형식으로 정의\n",
    "def MySQL_connect(user, password, db, host, port=3306):\n",
    "    url = 'mysql+mysqldb://{}:{}@{}:{}/{}'.format(user, password, host, port, db)\n",
    "    engine = sqlalchemy.create_engine(url, encoding='utf-8', echo=True)\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-07 16:56:26,537 INFO sqlalchemy.engine.Engine SELECT DATABASE()\n",
      "2022-11-07 16:56:26,538 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-11-07 16:56:26,630 INFO sqlalchemy.engine.Engine SELECT @@sql_mode\n",
      "2022-11-07 16:56:26,631 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-11-07 16:56:26,679 INFO sqlalchemy.engine.Engine SELECT @@lower_case_table_names\n",
      "2022-11-07 16:56:26,680 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-11-07 16:56:26,776 INFO sqlalchemy.engine.Engine CREATE DATABASE dogdogma;\n",
      "2022-11-07 16:56:26,776 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-11-07 16:56:26,830 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x27b40b47c70>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 연결 테스트용 코드 1\n",
    "engine = MySQL_connect('sixdogma', 'Poiu0987*', 'Anay', '54.250.124.140')\n",
    "engine.execute(\"CREATE DATABASE dogdogma;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-07 16:56:33,446 INFO sqlalchemy.engine.Engine DROP DATABASE dogdogma;\n",
      "2022-11-07 16:56:33,447 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-11-07 16:56:33,494 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x27b3f330730>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 연결 테스트용 코드 2\n",
    "engine.execute(\"DROP DATABASE dogdogma;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) 스케줄러 작동 여부 확인 : 에러 발생 → 주석 처리\n",
    "# MySQL 상에서 쿼리문으로 확인할 수 있다\n",
    "# engine.execute(\"SHOW VARIABLES LIKE 'event%';\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-07 11:45:18,984 INFO sqlalchemy.engine.Engine SET GLOBAL event_scheduler = ON;\n",
      "2022-11-07 11:45:18,984 INFO sqlalchemy.engine.Engine [raw sql] ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x1dd354ac940>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3) 스케줄러 켜기 : 정상 실행\n",
    "engine.execute(\"SET GLOBAL event_scheduler = ON;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-07 11:45:25,331 INFO sqlalchemy.engine.Engine SELECT @@global.time_zone, @@session.time_zone, now();\n",
      "2022-11-07 11:45:25,333 INFO sqlalchemy.engine.Engine [raw sql] ()\n"
     ]
    }
   ],
   "source": [
    "# (4) MySQL Time Zone 확인 : 정상 실행 BUT 표시되지는 않음\n",
    "# MySQL 상에서 쿼리문으로 확인할 수 있다\n",
    "engine.execute(\"SELECT @@global.time_zone, @@session.time_zone, now();\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5) 한국 시간에 맞게 Time Zone 변경\n",
    "# 코드로는 할 수 없고 직접 ubuntu로 들어가 mysql.conf.d 파일에서 수정을 해줘야 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] 파일 불러내고 전처리하는 함수 만들기\n",
    "\n",
    "이 과정을 scheduling할 필요가 있다\n",
    "\n",
    "pandas dataframe 전처리 작업을 spark로 할 수 있을까? 추후 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kemp-abh-sensor-2021.09.06.csv',\n",
       " 'kemp-abh-sensor-2021.09.07.csv',\n",
       " 'kemp-abh-sensor-2021.09.08.csv',\n",
       " 'kemp-abh-sensor-2021.09.09.csv',\n",
       " 'kemp-abh-sensor-2021.09.10.csv']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv 파일 경로 세팅 => 추후 linux file system 경로로 수정\n",
    "# root_dir : 기본 경로\n",
    "root_dir = r'C:\\Users\\admin\\Desktop\\FinalProject\\chromate\\chromate_data\\variable\\\\'\n",
    "# varfilelist : 기본 경로 안의 csv 파일 목록들\n",
    "varfilelist = natsort.natsorted(os.listdir(root_dir))\n",
    "varfilelist = [file for file in varfilelist if file.endswith('.csv')]\n",
    "varfilelist[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. csv 파일 하나 단위당 전처리하는 코드\n",
    "def PreProcessing(var_dir, var_list):\n",
    "    df = pd.read_csv(os.path.join(var_dir, var_list), engine='pyarrow')\n",
    "\n",
    "    # csv 파일명으로부터 'Date' 컬럼 만들어주기\n",
    "    df['Date'] = '-'.join(var_list.split('-')[-1].split('.')[:-1])\n",
    "\n",
    "    # 'Time' 컬럼 전처리 : 간단하게 할 수 있는 strftime, strptime 방법 찾아볼 것\n",
    "    adj_time = list()\n",
    "    for time in df['Time']:\n",
    "        tmp = time.split(':')\n",
    "        if tmp[0].split(' ')[0] == '오후':\n",
    "            tmp[0] = str(int(tmp[0].split(' ')[-1]) + 12)\n",
    "        else:\n",
    "            tmp[0] = tmp[0].split(' ')[-1]\n",
    "        tmp = ':'.join(tmp).split('.')[0]\n",
    "        adj_time.append(tmp)\n",
    "    df['Time'] = adj_time\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. csv 파일 전부 merge하고 정리하는 코드 \n",
    "def MergeFrame(var_dir, var_list):\n",
    "    # 우선 row 하나로 데이터프레임 만들어놓고 거기에 merge해나간다\n",
    "    var_df = PreProcessing(var_dir, var_list[0])\n",
    "    for i in range(1, len(var_list)):\n",
    "        var_df = pd.merge(var_df, PreProcessing(var_dir, var_list[i]), how='outer')\n",
    "        \n",
    "    # 열 순서 조정 및 필요없는 'Index' 컬럼 삭제\n",
    "    var_df = var_df[['Index', 'Date', 'Time', 'Lot', 'pH', 'Temp', 'Voltage']]\n",
    "    var_df.drop(columns=['Index'], inplace=True)\n",
    "\n",
    "    return var_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Lot</th>\n",
       "      <th>pH</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Voltage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-06</td>\n",
       "      <td>16:29:54</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>43.15</td>\n",
       "      <td>19.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-06</td>\n",
       "      <td>16:29:59</td>\n",
       "      <td>1</td>\n",
       "      <td>2.08</td>\n",
       "      <td>40.13</td>\n",
       "      <td>18.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-06</td>\n",
       "      <td>16:30:04</td>\n",
       "      <td>1</td>\n",
       "      <td>2.18</td>\n",
       "      <td>43.46</td>\n",
       "      <td>18.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-06</td>\n",
       "      <td>16:30:09</td>\n",
       "      <td>1</td>\n",
       "      <td>1.99</td>\n",
       "      <td>41.72</td>\n",
       "      <td>16.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-06</td>\n",
       "      <td>16:30:14</td>\n",
       "      <td>1</td>\n",
       "      <td>1.85</td>\n",
       "      <td>43.65</td>\n",
       "      <td>18.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50089</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>18:36:03</td>\n",
       "      <td>22</td>\n",
       "      <td>2.05</td>\n",
       "      <td>42.84</td>\n",
       "      <td>15.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50090</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>18:36:08</td>\n",
       "      <td>22</td>\n",
       "      <td>1.91</td>\n",
       "      <td>42.64</td>\n",
       "      <td>19.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50091</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>18:36:13</td>\n",
       "      <td>22</td>\n",
       "      <td>2.11</td>\n",
       "      <td>44.09</td>\n",
       "      <td>18.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50092</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>18:36:18</td>\n",
       "      <td>22</td>\n",
       "      <td>1.92</td>\n",
       "      <td>43.95</td>\n",
       "      <td>17.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50093</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>18:36:23</td>\n",
       "      <td>22</td>\n",
       "      <td>1.81</td>\n",
       "      <td>44.11</td>\n",
       "      <td>19.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50094 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date      Time  Lot    pH   Temp  Voltage\n",
       "0      2021-09-06  16:29:54    1  2.15  43.15    19.74\n",
       "1      2021-09-06  16:29:59    1  2.08  40.13    18.01\n",
       "2      2021-09-06  16:30:04    1  2.18  43.46    18.73\n",
       "3      2021-09-06  16:30:09    1  1.99  41.72    16.75\n",
       "4      2021-09-06  16:30:14    1  1.85  43.65    18.02\n",
       "...           ...       ...  ...   ...    ...      ...\n",
       "50089  2021-10-27  18:36:03   22  2.05  42.84    15.38\n",
       "50090  2021-10-27  18:36:08   22  1.91  42.64    19.08\n",
       "50091  2021-10-27  18:36:13   22  2.11  44.09    18.14\n",
       "50092  2021-10-27  18:36:18   22  1.92  43.95    17.96\n",
       "50093  2021-10-27  18:36:23   22  1.81  44.11    19.22\n",
       "\n",
       "[50094 rows x 6 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 함수가 제대로 만들어졌는지 확인해본다\n",
    "variable_df = MergeFrame(root_dir, varfilelist)\n",
    "variable_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3] MySQL에 업로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4] spark 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스파크를 사용하기 위해 가장 먼저 SparkContext라는 스파크 객체를 만들어주어야 한다.\n",
    "# SparkContext를 만들어 주기 위해서 우선 SparkSession을 만들어 주자.\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName('SparkExample')\n",
    "         .getOrCreate())\n",
    "\n",
    "# sparkContext로 객체 생성\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Index: integer (nullable = true)\n",
      " |-- Lot: integer (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- pH: double (nullable = true)\n",
      " |-- Temp: double (nullable = true)\n",
      " |-- Voltage: double (nullable = true)\n",
      "\n",
      "+-----+---+--------------+----+-----+-------+\n",
      "|Index|Lot|          Time|  pH| Temp|Voltage|\n",
      "+-----+---+--------------+----+-----+-------+\n",
      "|    1|  1|오후 4:29:54.0|2.15|43.15|  19.74|\n",
      "|    2|  1|오후 4:29:59.0|2.08|40.13|  18.01|\n",
      "|    3|  1|오후 4:30:04.0|2.18|43.46|  18.73|\n",
      "|    4|  1|오후 4:30:09.0|1.99|41.72|  16.75|\n",
      "|    5|  1|오후 4:30:14.0|1.85|43.65|  18.02|\n",
      "|    6|  1|오후 4:30:19.0|1.94|42.82|  19.27|\n",
      "|    7|  1|오후 4:30:24.0|1.94|43.17|   17.4|\n",
      "|    8|  1|오후 4:30:29.0|2.06|44.16|  18.69|\n",
      "|    9|  1|오후 4:30:34.0|1.97|41.79|  15.33|\n",
      "|   10|  1|오후 4:30:39.0|1.94|42.62|  17.44|\n",
      "|   11|  1|오후 4:30:44.0|2.14|40.61|  18.35|\n",
      "|   12|  1|오후 4:30:49.0|1.85|42.98|  19.24|\n",
      "|   13|  1|오후 4:30:54.0|2.16|43.76|  16.55|\n",
      "|   14|  1|오후 4:30:59.0|1.88|41.33|  18.34|\n",
      "|   15|  1|오후 4:31:04.0|1.99|41.47|  16.04|\n",
      "|   16|  1|오후 4:31:09.0|1.88|43.75|  17.38|\n",
      "|   17|  1|오후 4:31:14.0|2.03|40.82|  15.08|\n",
      "|   18|  1|오후 4:31:19.0|2.12|42.94|  18.67|\n",
      "|   19|  1|오후 4:31:24.0|1.96|41.02|  19.39|\n",
      "|   20|  1|오후 4:31:29.0|2.06|44.11|  17.04|\n",
      "+-----+---+--------------+----+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 스파크로 csv 파일 읽어보기\n",
    "df = (spark.read.format('csv')\n",
    "      .option(\"inferSchema\", \"True\")\n",
    "      .option(\"header\", \"true\")\n",
    "      .load(os.path.join(root_dir, varfilelist[0])))\n",
    "\n",
    "df.createOrReplaceTempView('df_table')\n",
    "\n",
    "df.printSchema()  # 스키마 형태 볼 수 있음\n",
    "df.show()         # 가상의 테이블을 만들어 데이터프레임을 볼 수 있음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bf0d51478355d2251941b3b98616086516a0eddd7c72ee47a3371765770709a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
